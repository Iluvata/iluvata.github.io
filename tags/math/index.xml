<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>math on Iluvata&#39;s Blog</title>
    <link>https://iluvata.github.io/tags/math/</link>
    <description>Recent content in math on Iluvata&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 19 Apr 2021 19:00:13 +0800</lastBuildDate><atom:link href="https://iluvata.github.io/tags/math/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>最大似然估计与基本演绎法</title>
      <link>https://iluvata.github.io/post/2021-04-19_likehood-reasoning/</link>
      <pubDate>Mon, 19 Apr 2021 19:00:13 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-04-19_likehood-reasoning/</guid>
      <description>在数理统计中，极大似然估计是一种使用已知样本来反推最大概率的模型参数的方法。比如我们知道（或者推测）某个 随机变量服从正态分布，但是不知道分布的参数值。如果我们能够获取到几个分布中的样本，就可以对其进行拟合，尝试 得到最有可能的参数值来确定该分布。那具体要怎么通过样本来得到分布的参数呢？
 极大似然估计使用了一种最符合直觉的方法，即使用取到这些样本组合概率最大的参数。这个过程和福尔摩斯使用的基本演绎法 及其相似。在《四签名》中，福尔摩斯在推理凶手的逃跑路线（没想到吧jojo，这就是我的逃跑路线啊，wryyyyy 23333） 的时候说，当你排除了所有不可能的情况后，剩下的，不管多不可能，就是事实。类似的方法还在《巴斯克维尔的猎犬》中 福尔摩斯推断来访者身份以及许多其他地方中使用过。如果把你扔到二等车厢，让你指出每个人的职业，你会怎么做。首先 当然是对对象进行观察，观察他们的衣着，膝盖，手腕，衣领。得到的结果，比如说一个人的膝盖上有泥土，就是数理统计 中的样本。给定了一系列的样本，如手腕上有粉末，衣领上有灰，脚上穿着皮鞋，戴着眼镜；这些结合在一起得到了样本空间。 我们会怎么推断这个人的职业呢？符合这些样本情况的职业可能有很多，还可能有一些样本是由于一些意外的活动引起的。但是一般 来说，我们不会把这个人的职业判断成运动员。尽管由于一系列的小概率事件使得一位运动员打扮成这样，但我们的推理是基于 最有可能导致这些样本的情况进行的。这也就是最大似然的思想方式。
 回到概率统计中，那在数学上该如何计算参数值呢？我们将几个样本值分别带入分布公式，要求的参数作为变量，将每个样本 得到的对应概率表达式相乘作为联合概率（需要各样本相互独立），把取到使得该联合概率最大的值拿来当作目标参数值。 再往下更具体的计算步骤包括处理联合概率（即极大似然目标函数），希望求解使其最大化的最优化问题。一般的方法是 对其做对数处理，然后求导，使得导数为0的参数值能让目标函数取到极大值，就是我们要求的值了。</description>
    </item>
    
    <item>
      <title>概率统计中的分布</title>
      <link>https://iluvata.github.io/post/2021-03-19_distributions/</link>
      <pubDate>Fri, 19 Mar 2021 14:52:58 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-19_distributions/</guid>
      <description> 连续分布  均匀分布   正态分布  距离某一中心值偏离的误差越大的概率越小。可用于自然界许多现象的模拟.
  指数分布  EX=1/lambda DX=1/lambda^2 指数分布的无记忆性：先验概率与后验概率相同。可用于模拟电器使用：不管之前使用了多久， 能继续使用x小时的概率不变。 先验概率 后验概率
    离散分布  0-1分布  0-1分布随机变量取值为0或1，参数只有一个p，即取值为1的概率。
  二项分布  二项分布是多个相同0-1分布的叠加。B(n,p)中n为随机变量的数量，p和0-1分布中相同。 输入k得到的结果为k个随机变量得到1的概率。
  泊松分布  EX=DX=lambda 在二项分布数值非常大的时候B(1000, 0.001), n=1000, p=0.001的时候计算量非常大。 可以用泊松分布进行模拟。lambda=n*p, 随机变量为k. 经常被用来模拟排队。在每个离散时间一个客户可能来的概率为p, 泊松分布可以模拟 总客户数为n时在时间点k来的客户数量。
    </description>
    </item>
    
    <item>
      <title>欧拉环路和汉密尔顿环路</title>
      <link>https://iluvata.github.io/post/2021-03-04_euler-circuit-and-hamiltonian-circuit/</link>
      <pubDate>Thu, 04 Mar 2021 17:54:59 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-04_euler-circuit-and-hamiltonian-circuit/</guid>
      <description>图论中有两种重要的特殊图：欧拉图和汉密尔顿图，各表示能够找到欧拉环路与汉密尔顿环路的图。 欧拉环路是由七桥问题来的：如何走过7座桥回到起点。在一般的图中，该问题可以被表示为：能不能找到 一条经过所有边，最后回到源点的环路。
 欧拉路径是比欧拉环路更广的概念。欧拉路径即图中经过所有边一次的简单路径，不要求终点和源点为 同一点。汉密尔顿路径与之类似，只是要求的不是经过所有边一次而是经过所有点一次。汉密尔顿环路 即起点与终点在同一点的汉密尔顿路径，汉密尔顿图即能找出汉密尔顿路径的图。
 对于欧拉图的判定最早由欧拉提出。方法很简单：图中每个点的度必须为偶数。判断欧拉路径的方法是 除了两个点外每个点的度数都为偶数，那两个点的度都为奇数。我们可以想象边经过一点的过程，如果 想要经过每条边一次，那每次入射一点后必定需要从另一条新的边出去。就像在一根线上串珠子的过程。 对于欧拉路径，除了头和尾两个点的度为奇数，其他都是偶数。对于欧拉环路来说头和尾是同一点， 从该点射出的路径最终还是要通过另一边回到该点。因此欧拉图所有点的度数都为偶数。
 和欧拉图不同，汉密尔顿图没有已知的多项式时间判定方法。事实上，汉密尔顿图的判定是NP完全问题。 虽然没有找到判断汉密尔顿图的充要条件，但是已知的有充分条件。n&amp;gt;=3个节点的简单图上，任意一对非 邻接节点的度数和&amp;gt;=n.或者，任意节点的度&amp;gt;=n/2.</description>
    </item>
    
    <item>
      <title>理解动态规划与warshall算法</title>
      <link>https://iluvata.github.io/post/2021-02-19_dp-and-warshall/</link>
      <pubDate>Fri, 19 Feb 2021 13:35:34 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-02-19_dp-and-warshall/</guid>
      <description>今天刚好在离散里学了用来计算传递闭包的warshall算法，就在这里把离散里计算闭包的算法 和动态规划一起整理一下。
集合、关系和闭包  要理解闭包首先需要了解集合和关系（函数）。 在离散数学中我们讨论的集合都是非公理化的朴素集合论（会导致罗素悖论）。有时间可以了解下公理集合论。
关系与函数  关系： 关系是一个集合中的元素到另一个集合中元素的映射方式。二元关系是两个集合笛卡尔积的子集。 关系能够具有的性质包括自反性，对称性，传递性，反自反性，反对称性。具有自反、堆成、传递性 的关系称为等价关系。其他的特殊关系有偏序（包含全序、良序、字典序）
 函数：函数可以看作一种特殊的关系。 函数是每个定义域中元素到唯一一个值域中元素的映射.
 A function from A to B is an assignment of exactly one element of B to each element of A.
 函数的种类包括
  单射 一一对应(one-to-one)函数：如果定义域中的两个元素不相等，那值域中对应的两个元素也肯定不相等.
  满射（onto）函数：值域中每个值都有对应的定义域元素.
  双射： 满足单射及满射
    闭包  闭包：一个集合具有某个性质的最小超集。例如在一个集合S上关系R的自反闭包是R并S0, S0是集合S中所有元素到自身关系的集合。 其他常用的闭包还有对称闭包和传递闭包。自反闭包记作r(R),对称闭包s(R),传递闭包t(R).
 一个关系的自反闭包与对称闭包计算都很简单，传递闭包要麻烦些。一个具有传递性的关系是指在该关系中， 如果出现了(a,b)和(b,c)，则(a,c)也存在。想得到一个关系具有传递性的最小超集，我们要检查当前该关系中所有满足(a,b) (b,c) 的pair，得到(a,c)后加入。但是只进行一次后不一定能得到我们想要的传递性关系。比如原先关系R为{(a,b), (b,c), (c,d)}, 进行一次计算后得到的R1是{(a,b), (b,c), (c,d), (a,c), (b,d)}。R1中存在(a,b)和(b,d)，但是没有(a,d)，并不是我们想要的 自反闭包。我们需要再做一次相同的步骤。在一个无穷关系中，相同的步骤需要执行无穷次。这就是计算传递闭包的算法。</description>
    </item>
    
  </channel>
</rss>
