<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>learning on Iluvata&#39;s Blog</title>
    <link>https://iluvata.github.io/categories/learning/</link>
    <description>Recent content in learning on Iluvata&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 04 Mar 2021 17:54:59 +0800</lastBuildDate><atom:link href="https://iluvata.github.io/categories/learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>欧拉环路和汉密尔顿环路</title>
      <link>https://iluvata.github.io/post/2021-03-04_euler-circuit-and-hamiltonian-circuit/</link>
      <pubDate>Thu, 04 Mar 2021 17:54:59 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-04_euler-circuit-and-hamiltonian-circuit/</guid>
      <description>图论中有两种重要的特殊图：欧拉图和汉密尔顿图，各表示能够找到欧拉环路与汉密尔顿环路的图。 欧拉环路是由七桥问题来的：如何走过7座桥回到起点。在一般的图中，该问题可以被表示为：能不能找到 一条经过所有边，最后回到源点的环路。
 欧拉路径是比欧拉环路更广的概念。欧拉路径即图中经过所有边一次的简单路径，不要求终点和源点为 同一点。汉密尔顿路径与之类似，只是要求的不是经过所有边一次而是经过所有点一次。汉密尔顿环路 即起点与终点在同一点的汉密尔顿路径，汉密尔顿图即能找出汉密尔顿路径的图。
 对于欧拉图的判定最早由欧拉提出。方法很简单：图中每个点的度必须为偶数。判断欧拉路径的方法是 除了两个点外每个点的度数都为偶数，那两个点的度都为奇数。我们可以想象边经过一点的过程，如果 想要经过每条边一次，那每次入射一点后必定需要从另一条新的边出去。就像在一根线上串珠子的过程。 对于欧拉路径，除了头和尾两个点的度为奇数，其他都是偶数。对于欧拉环路来说头和尾是同一点， 从该点射出的路径最终还是要通过另一边回到该点。因此欧拉图所有点的度数都为偶数。
 和欧拉图不同，汉密尔顿图没有已知的多项式时间判定方法。事实上，汉密尔顿图的判定是NP完全问题。 虽然没有找到判断汉密尔顿图的充要条件，但是已知的有充分条件。n&amp;gt;=3个节点的简单图上，任意一对非 邻接节点的度数和&amp;gt;=n.或者，任意节点的度&amp;gt;=n/2.</description>
    </item>
    
    <item>
      <title>电脑是怎么启动的</title>
      <link>https://iluvata.github.io/post/2021-03-01_how-computer-startup/</link>
      <pubDate>Mon, 01 Mar 2021 22:52:59 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-03-01_how-computer-startup/</guid>
      <description>x86启动过程简介  x86计算机开机过程大致可以被分为几个阶段：
  按下开机键
  CPU跳转至BIOS物理地址
  BIOS进行开机自检
  寻找启动设备
  从MBR加载启动区
  BIOS转移控制给BootLoader
  第一阶段：硬件  BIOS  Basic Input/Output System 基本输入输出系统，被固化在ROM上的一组程序，提供最底层对硬件的控制。 也被称为固件。
UEFI  Unified Extensible Firmware Interface 统一可拓展固件接口。堆栈传参，动态链接，更大寻址。
    MBR  Master Boot Record 主引导记录。硬盘的第一个扇区，存放预启动信息、分区表信息。
    第二阶段：系统软件  Boot Loader  操作系统内核加载器。初始化硬件，建立内存空间映射。
  GRUB
  LILO
    加载内核  根据grub设定的内核映像所在路径读取，解压，放入内存。初始化函数，设备，建立Linux核心环境（初始化寄存器、堆栈）。</description>
    </item>
    
    <item>
      <title>理解贪心算法与Dijkstra算法</title>
      <link>https://iluvata.github.io/post/2021-02-24_greedy-and-dijkstra/</link>
      <pubDate>Wed, 24 Feb 2021 10:52:06 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-02-24_greedy-and-dijkstra/</guid>
      <description>贪心与动态规划  我们知道动态规划求解的问题需要具有   最优子结构   重复子问题   具有最优子结构的问题有时也可以用贪心算法求解。条件是最优解中只包含一个子问题的最优解，而一般的动态规划 最优解包含多个子问题的最优解。比如fib算法，fib(5)需要fib(4)与fib(3)两个子问题的解，无法使用贪心算法。 阶乘算法factorial(5)的递归解只需要使用一个子问题factorial(4)的解，这种情况使用贪心算法，即无需自底向上 记录每一子问题的解，只需记录当前最近一子问题的解用于求解当前解。
 一个更直观的例子是0-1背包问题和部分背包问题。背包问题要求在指定的一些商品中选出能装入背包重量的最大价值的商品 组合。0-1背包问题中的每个商品是一个整体，要么整个装入，要么不装。部分背包问题里的商品类似水或金沙，可以分割后 装入部分。0-1背包问题是典型的动态规划例子，而部分背包则可以用贪心。
 我们容易得到背包问题的最优子结构：要求重量的最优解包含了背包去掉某个物品重量后的最优解。考虑所有物品的最优解中 包含了考虑其中部分物品得到的最优解。对于0-1背包问题，通过以上两个维度我们可以列出状态转移方程：从考虑0个物品开始 依次加入每个物品，重量从0开始递增至所给背包重量；当前重量下考虑了当前加入所有物品能得到的最大价值 = max{(当前最大重量减去 当前物品重量后，不考虑当前物品能得到的最大价值 + 当前物品价值), (同等重量，不考虑当前物品能得到的最大价值),( 考虑了当前物品，最大重量-1时能得到的最大价值)}. 对于部分背包问题，如果还是使用0-1背包的方法来求解，我们会发现这次 要求的重量都是连续的，每次递增的重量无法确定。但是不妨假设我们可以每次递增无穷小的重量，就容易看出每次状态转移时， 能得到最大价值的选择一定是从剩余物品中（价值/重量）比例最大的物品中抽取加入。这样每次求最优解用到的唯一一个最优 子问题就能被确定下来，我们可以直接使用贪心算法，即，永远在剩余物品中选择（价值/重量）比例最大的物品加入，直到包 满。
 另一个例子是活动选择问题。对几个互相竞争的活动进行调度，希望找出一个最大的相互兼容活动集合。给出每个活动的开始时间与持续时长， 我们希望得到一定时间段内所能容纳的最多活动数量（多个活动间不能有重叠时间）。容易找到这个问题的最优子结构：每个活动将整体时间分为 两部分：该活动前的时间与该活动后的时间。在这两段时间内我们都需要最大化执行任务数，两段的任务数之和+1，所得的就是整个时间段的最优 解。找到最优子结构后就不难得到动态规划算法了。我们知道在这个问题的最优解中包含了两个子问题的最优解，即：活动左边时间段最优解与右边时间段 最优解。如果我们进一步观察，可以发现如果我们将选择的当前活动限制为当前时间段后开始并能最早执行完的活动，得到当前最优解所需的子问题 就只剩一个：当前活动后的时间段。可以证明该贪心选择能够得到最优解。通过一个简单的变换，我们将原来需要2个子问题的解变成了只需要1个子问题的解。 这种情况下，我们无需记录所有子问题的解来进行动态规划自底向上求解当前解，只需要记录前一子问题的解，自顶向下求解问题。
 一些能够轻易看出使用动态规划求解的问题，可以思考能不能通过变换求解过程得到贪心策略来进一步优化，给出贪心算法。
  贪心策略的基本内容  使用贪心算法需要的条件有两个：
  贪心选择性质
  最优子结构
  贪心选择性质即上文中我们说的“能找到只包含一个子问题的最优解“。通过适当的变换，一些问题可以找到贪心选择性质，如上文中的活动调度问题。 最优子结构即动态规划中的“由子问题的最优解构成当前问题最优解”的性质。满足这两个条件的问题即可使用贪心算法。但在有些情况下，不能轻易找出 最优子结构，但是问题的确可以使用贪心算法求解。比如PAT-1067.
  Dijkstra算法与Bellman-Ford算法  Dijkstra算法  作为图论中几乎是最有名的算法，Dijkstra算法解决了最短路径问题。从算法思想的角度来说，Dijkstra算法使用了贪心策略。与之相对的是 Bellman-Ford算法。同为计算最短路径的算法，Bellman-Ford算法使用了动态规划的思想，复杂度为O(n^3)。Dijkstra算法在此基础上 进一步限定条件（Bellman-Ford算法可以用来计算带有负权的图，Dijkstra只能用于权值为正数的情况）利用了问题具有贪心选择性质，用贪心策略 将最短路径算法的复杂度进一步减到了O(n^2).</description>
    </item>
    
    <item>
      <title>理解动态规划与warshall算法</title>
      <link>https://iluvata.github.io/post/2021-02-19_dp-and-warshall/</link>
      <pubDate>Fri, 19 Feb 2021 13:35:34 +0800</pubDate>
      
      <guid>https://iluvata.github.io/post/2021-02-19_dp-and-warshall/</guid>
      <description>今天刚好在离散里学了用来计算传递闭包的warshall算法，就在这里把离散里计算闭包的算法 和动态规划一起整理一下。
集合、关系和闭包  要理解闭包首先需要了解集合和关系（函数）。 在离散数学中我们讨论的集合都是非公理化的朴素集合论（会导致罗素悖论）。有时间可以了解下公理集合论。
关系与函数  关系： 关系是一个集合中的元素到另一个集合中元素的映射方式。二元关系是两个集合笛卡尔积的子集。 关系能够具有的性质包括自反性，对称性，传递性，反自反性，反对称性。具有自反、堆成、传递性 的关系称为等价关系。其他的特殊关系有偏序（包含全序、良序、字典序）
 函数：函数可以看作一种特殊的关系。 函数是每个定义域中元素到唯一一个值域中元素的映射.
 A function from A to B is an assignment of exactly one element of B to each element of A.
 函数的种类包括
  单射 一一对应(one-to-one)函数：如果定义域中的两个元素不相等，那值域中对应的两个元素也肯定不相等.
  满射（onto）函数：值域中每个值都有对应的定义域元素.
  双射： 满足单射及满射
    闭包  闭包：一个集合具有某个性质的最小超集。例如在一个集合S上关系R的自反闭包是R并S0, S0是集合S中所有元素到自身关系的集合。 其他常用的闭包还有对称闭包和传递闭包。自反闭包记作r(R),对称闭包s(R),传递闭包t(R).
 一个关系的自反闭包与对称闭包计算都很简单，传递闭包要麻烦些。一个具有传递性的关系是指在该关系中， 如果出现了(a,b)和(b,c)，则(a,c)也存在。想得到一个关系具有传递性的最小超集，我们要检查当前该关系中所有满足(a,b) (b,c) 的pair，得到(a,c)后加入。但是只进行一次后不一定能得到我们想要的传递性关系。比如原先关系R为{(a,b), (b,c), (c,d)}, 进行一次计算后得到的R1是{(a,b), (b,c), (c,d), (a,c), (b,d)}。R1中存在(a,b)和(b,d)，但是没有(a,d)，并不是我们想要的 自反闭包。我们需要再做一次相同的步骤。在一个无穷关系中，相同的步骤需要执行无穷次。这就是计算传递闭包的算法。</description>
    </item>
    
  </channel>
</rss>
